{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Make Frequency Dependence Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and funcs\n",
    "%matplotlib widget\n",
    "from brian2 import *\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import diagonal_sums as ds\n",
    "import time\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frequency and learning efficiency from all datasets\n",
    "ndataset = 5\n",
    "nsize = 2\n",
    "nduty = 3\n",
    "nfreq = 15\n",
    "ngain = 2\n",
    "nnodes = 500\n",
    "frequency = np.zeros((ndataset,nsize*nduty*nfreq*ngain)) # reshape later\n",
    "weight_profile = np.zeros((ndataset,nsize*nduty*nfreq*ngain,nnodes))\n",
    "learning_efficiency = np.zeros((ndataset,nsize*nduty*nfreq))\n",
    "\n",
    "# for frequency calcs\n",
    "tmin = 20\n",
    "tmax = 120\n",
    "nbin = 40\n",
    "\n",
    "for dataset in range(ndataset):\n",
    "    with open('frequency_dependence_data'+str(dataset+1)+'.pkl', 'rb') as f:\n",
    "        mylist = pickle.load(f)\n",
    "    net_sizes = mylist[0]\n",
    "    stim_duties = mylist[1]\n",
    "    stim_frequencies = mylist[2]\n",
    "    attractor_nodes = mylist[3]\n",
    "    gain_record = mylist[4]\n",
    "    time_record = mylist[5]\n",
    "    spike_record = mylist[6]\n",
    "    weight_record = mylist[7]\n",
    "    attractor_size = len(attractor_nodes)\n",
    "    attractor_index = {e:i for i,e in enumerate(attractor_nodes)} # lookup dictionary for getting attractor index from node number    \n",
    "    \n",
    "    for rec in range(nsize*nduty*nfreq*ngain):\n",
    "        # Calculate frequency\n",
    "        spikes_in_attractor = np.isin(spike_record[rec],attractor_nodes)\n",
    "        z = spike_record[rec][spikes_in_attractor]\n",
    "        spikes = np.ndarray(z.shape)\n",
    "        for node in attractor_index:\n",
    "            spikes[z==node] = attractor_index[node]\n",
    "        t = time_record[rec][spikes_in_attractor]\n",
    "        points_in_window = (t>tmin) & (t<tmax)\n",
    "        t = t[points_in_window]\n",
    "        spikes = spikes[points_in_window]\n",
    "        real,timeline = np.histogram(t,bins=nbin,weights=np.cos(2.0*np.pi*spikes/attractor_size))\n",
    "        imag,timeline = np.histogram(t,bins=nbin,weights=np.sin(2.0*np.pi*spikes/attractor_size))\n",
    "        timeline = 0.5 * (timeline[:-1]+timeline[1:])\n",
    "        cplx = real + 1.j * imag\n",
    "        phase = np.unwrap(np.angle(cplx))\n",
    "        p = np.polyfit(timeline,phase,1,w=np.absolute(cplx))\n",
    "        frequency[dataset,rec] = 1000. * p[0] / (2.*np.pi)\n",
    "        \n",
    "        # Calculate weight profile\n",
    "        weight_profile[dataset,rec] = ds.diagonal_sums(weight_record[rec])\n",
    "    learning_efficiency[dataset,:] = 1./np.array(gain_record)\n",
    "\n",
    "frequency = np.reshape(frequency,(ndataset,nsize,nduty,nfreq,ngain))\n",
    "weight_profile = np.reshape(weight_profile,(ndataset,nsize,nduty,nfreq,ngain,nnodes))\n",
    "learning_efficiency = np.reshape(learning_efficiency,(ndataset,nsize,nduty,nfreq))\n",
    "\n",
    "mylist = [stim_duties, stim_frequencies, frequency, weight_profile, learning_efficiency]\n",
    "with open('frequency_dependence_data_preprocessed.pkl', 'wb') as f:\n",
    "    pickle.dump(mylist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('frequency_dependence_data_preprocessed.pkl', 'rb') as f:\n",
    "    mylist = pickle.load(f)\n",
    "stim_duties = mylist[0]\n",
    "stim_frequencies = mylist[1]\n",
    "frequency = mylist[2]\n",
    "weight_profile = mylist[3]\n",
    "learning_efficiency = mylist[4]\n",
    "ndataset,nsize,nduty,nfreq,ngain,nnodes = weight_profile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 3 15 2 500 (5, 2, 3, 15, 2) (2, 3, 15, 2)\n",
      "(2, 3, 15, 2) (2, 3, 15, 2)\n",
      "(5, 2, 3, 15)\n"
     ]
    }
   ],
   "source": [
    "print(ndataset,nsize,nduty,nfreq,ngain,nnodes,frequency.shape,np.std(frequency,0).shape)\n",
    "frequency_mean = np.mean(frequency,0)\n",
    "frequency_std = np.std(frequency,0)\n",
    "\n",
    "print(frequency_mean.shape,frequency_std.shape)\n",
    "print(learning_efficiency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    <ipython-input-82-554b069f4a30>:8: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  figure(figsize=(12,4))\n",
      " [py.warnings]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd004b234d543babedbf82b7400e10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frequency_mean = np.mean(frequency,0)\n",
    "frequency_std = np.std(frequency,0)\n",
    "learning_efficiency_mean = np.mean(learning_efficiency,0)\n",
    "learning_efficiency_std = np.std(learning_efficiency,0)\n",
    "weight_profile_mean = np.mean(weight_profile,0)\n",
    "weight_profile_std = np.std(weight_profile,0)\n",
    "\n",
    "figure(figsize=(12,4))\n",
    "subplot(131)\n",
    "#errorbar(stim_frequencies,np.reshape(frequency_mean[0,0,:,0],(-1,15)).T,np.reshape(frequency_std[0,0,:,0],(-1,15)).T,color='k',fmt='--')\n",
    "plot(stim_frequencies,frequency_mean[1,0,:,0],linewidth=3,label='15cm, d=0.125')\n",
    "plot(stim_frequencies,frequency_mean[1,1,:,0],linewidth=3,label='15cm, d=0.250')\n",
    "plot(stim_frequencies,frequency_mean[1,2,:,0],linewidth=3,label='15cm, d=0.500')\n",
    "plot(stim_frequencies,frequency_mean[0,0,:,0],label='1cm, d=0.125')\n",
    "plot(stim_frequencies,frequency_mean[0,1,:,0],label='1cm, d=0.250')\n",
    "plot(stim_frequencies,frequency_mean[0,2,:,0],label='1cm, d=0.500')\n",
    "plot(stim_frequencies,frequency_mean[1,0,:,1],'tab:blue',linewidth=3,linestyle='dotted')\n",
    "plot(stim_frequencies,frequency_mean[1,1,:,1],'tab:orange',linewidth=3,linestyle='dotted')\n",
    "plot(stim_frequencies,frequency_mean[1,2,:,1],'tab:green',linewidth=3,linestyle='dotted')\n",
    "plot(stim_frequencies,frequency_mean[0,0,:,1],'tab:red',linestyle='dotted')\n",
    "plot(stim_frequencies,frequency_mean[0,1,:,1],'tab:purple',linestyle='dotted')\n",
    "plot(stim_frequencies,frequency_mean[0,2,:,1],'tab:brown',linestyle='dotted')\n",
    "#yscale('log')\n",
    "xlabel('Driving Frequency (Hz)')\n",
    "ylabel('Self-oscillation Frequency (Hz)')\n",
    "axis([0,21,0,120])\n",
    "#legend()\n",
    "\n",
    "subplot(132)\n",
    "learning_efficiency_norm = learning_efficiency_mean.copy()\n",
    "learning_efficiency_norm[:,0,:] *= 2 # d=0.125 has a 2x handicap vs 0.25\n",
    "learning_efficiency_norm[:,2,:] /= 2 # d=0.5 had a 2x advantage over 0.25\n",
    "learning_efficiency_norm /= np.amax(learning_efficiency_norm)\n",
    "plot(stim_frequencies,learning_efficiency_norm[1,0,:],linewidth=3,label='15cm, d=0.125')\n",
    "plot(stim_frequencies,learning_efficiency_norm[1,1,:],linewidth=3,label='15cm, d=0.250')\n",
    "plot(stim_frequencies,learning_efficiency_norm[1,2,:],linewidth=3,label='15cm, d=0.500')\n",
    "plot(stim_frequencies,learning_efficiency_norm[0,0,:],label='1cm, d=0.125')\n",
    "plot(stim_frequencies,learning_efficiency_norm[0,1,:],label='1cm, d=0.250')\n",
    "plot(stim_frequencies,learning_efficiency_norm[0,2,:],label='1cm, d=0.500')\n",
    "legend()\n",
    "xlabel('Driving Frequency (Hz)')\n",
    "ylabel('Relative Learning Efficiency $\\eta$')\n",
    "axis([0,21,0,1.05])\n",
    "\n",
    "subplot(133)\n",
    "#plot(np.arange(nnodes)-nnodes/2,np.reshape(weight_profile_mean[:,1,(0,14),0,:],(-1,nnodes)).T)\n",
    "plot(np.arange(nnodes)-nnodes/2,weight_profile_mean[1,1,0,0,:],'tab:orange',label='15cm, f=1Hz')\n",
    "plot(np.arange(nnodes)-nnodes/2,weight_profile_mean[1,1,14,0,:],'tab:orange',linestyle='dotted',label='15cm, f=20Hz')\n",
    "plot(np.arange(nnodes)-nnodes/2,weight_profile_mean[0,1,0,0,:],'tab:purple',label='1cm, f=1Hz')\n",
    "plot(np.arange(nnodes)-nnodes/2,weight_profile_mean[0,1,14,0,:],'tab:purple',linestyle='dotted',label='1cm, f=20Hz')\n",
    "conduction_delay = 12.54e-3\n",
    "k = -conduction_delay * frequency_mean[1,1,0,0] * nnodes\n",
    "plot([k,k],[0,100],'tab:orange')\n",
    "k = -conduction_delay * frequency_mean[1,1,14,0] * nnodes\n",
    "plot([k,k],[0,100],'tab:orange',linestyle='dotted')\n",
    "conduction_delay = 3.64e-3\n",
    "k = -conduction_delay * frequency_mean[0,1,0,0] * nnodes\n",
    "plot([k,k],[0,100],'tab:purple')\n",
    "k = -conduction_delay * frequency_mean[0,1,14,0] * nnodes\n",
    "plot([k,k],[0,100],'tab:purple',linestyle='dotted')\n",
    "xlabel('Diagonal Number (k)')\n",
    "ylabel('Sum of Diagonal')\n",
    "legend()\n",
    "\n",
    "tight_layout()\n",
    "savefig('FIG2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually check frequency fits to see if any failed\n",
    "# Display spikes and fits in batches of 30 simulations\n",
    "# There are 5 datasets and 180 simulations (6 batches) per dataset\n",
    "# Read in one dataset using this cell, and change the value of start [0,30,60,90,120,150]\n",
    "#  in the next cell to plot the fits\n",
    "dataset = 4\n",
    "with open('frequency_dependence_data'+str(dataset)+'.pkl', 'rb') as f:\n",
    "    mylist = pickle.load(f)\n",
    "net_sizes = mylist[0]\n",
    "stim_duties = mylist[1]\n",
    "stim_frequencies = mylist[2]\n",
    "attractor_nodes = mylist[3]\n",
    "gain_record = mylist[4]\n",
    "time_record = mylist[5]\n",
    "spike_record = mylist[6]\n",
    "weight_record = mylist[7]\n",
    "attractor_size = len(attractor_nodes)\n",
    "attractor_index = {e:i for i,e in enumerate(attractor_nodes)} # lookup dictionary for getting attractor index from node number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db0580791db4fd3ba9e077504c71edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx=2\n",
    "ny=15\n",
    "figure(figsize=(4*nx,4*ny))\n",
    "\n",
    "tmin = 20\n",
    "tmax = 120\n",
    "nbin = 40\n",
    "batch = 30\n",
    "start = 60 # [0,30,60,90,120,150]\n",
    "for i in range(batch):\n",
    "    rec = start + i\n",
    "    spikes_in_attractor = np.isin(spike_record[rec],attractor_nodes)\n",
    "    z = spike_record[rec][spikes_in_attractor]\n",
    "    spikes = np.ndarray(z.shape)\n",
    "    for node in attractor_index:\n",
    "        spikes[z==node] = attractor_index[node]\n",
    "    t = time_record[rec][spikes_in_attractor]\n",
    "    points_in_window = (t>tmin) & (t<tmax)\n",
    "    t = t[points_in_window]\n",
    "    spikes = spikes[points_in_window]\n",
    "    real,timeline = np.histogram(t,bins=nbin,weights=np.cos(2.0*np.pi*spikes/attractor_size))\n",
    "    imag,timeline = np.histogram(t,bins=nbin,weights=np.sin(2.0*np.pi*spikes/attractor_size))\n",
    "    timeline = 0.5 * (timeline[:-1]+timeline[1:])\n",
    "    cplx = real + 1.j * imag\n",
    "    phase = np.unwrap(np.angle(cplx))\n",
    "    p = np.polyfit(timeline,phase,1,w=np.absolute(cplx))\n",
    "    freq = 1000. * p[0] / (2.*np.pi)\n",
    "    subplot(ny,nx,i+1)\n",
    "    plot(t,spikes,'k.')\n",
    "    plot(timeline,(attractor_size / (2.*np.pi) * (p[1] + timeline * p[0])) % attractor_size,'ro-')\n",
    "    title(str(freq)+'Hz')\n",
    "\n",
    "tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.15098342 0.24664241 0.29146515 0.31335723 0.32485336 0.33111658\n",
      "   0.32940172 0.32481615 0.3197728  0.31821241 0.31716387 0.31434491\n",
      "   0.30889889 0.30844046 0.29677755]\n",
      "  [0.27795564 0.53043011 0.68749167 0.79333562 0.85932178 0.88200297\n",
      "   0.88788803 0.87450742 0.87566628 0.85275067 0.80482101 0.75673093\n",
      "   0.70336424 0.66089827 0.63594343]\n",
      "  [0.38209952 0.81233368 1.1855139  1.45661741 1.64778072 1.77141421\n",
      "   1.81610989 1.83950786 1.83131524 1.7834398  1.68699729 1.55167352\n",
      "   1.42881068 1.32412226 1.22873979]]\n",
      "\n",
      " [[0.13282677 0.22309402 0.25222483 0.27866336 0.29542505 0.28318891\n",
      "   0.28234353 0.28091735 0.27487918 0.27844159 0.28312314 0.25441669\n",
      "   0.25954007 0.25067932 0.24153547]\n",
      "  [0.25190503 0.46470434 0.60380242 0.69353184 0.76488025 0.77603856\n",
      "   0.77755913 0.79341181 0.79640219 0.71849639 0.72103348 0.64787197\n",
      "   0.6087066  0.55179011 0.51573692]\n",
      "  [0.34382899 0.7366392  1.05119868 1.29971028 1.43603158 1.54252715\n",
      "   1.6844209  1.6067486  1.6554515  1.55783191 1.46448352 1.41181492\n",
      "   1.23129472 1.0843116  1.05706051]]]\n"
     ]
    }
   ],
   "source": [
    "print(learning_efficiency_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1435008750411746"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.87450742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2603795247262577"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.79341181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2447498009333882"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/1.6067486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.157329307671431"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/0.32481615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.10890552034421"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/0.24664241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8920392740809135"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/1.05706051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.16634178 0.25453642 0.29173789 0.30421866 0.32507937 0.33074935\n",
      "    0.32694764 0.33268356 0.32140615 0.31781502 0.31430325 0.31604938\n",
      "    0.30260047 0.30260047 0.2962963 ]\n",
      "   [0.27089947 0.53668763 0.69189189 0.79503106 0.83660131 0.85333333\n",
      "    0.88275862 0.86486486 0.86486486 0.81528662 0.75739645 0.74418605\n",
      "    0.69189189 0.65139949 0.62745098]\n",
      "   [0.36702509 0.79503106 1.16363636 1.41436464 1.6        1.7414966\n",
      "    1.82857143 1.79020979 1.81560284 1.72972973 1.6516129  1.55151515\n",
      "    1.40659341 1.30612245 1.19626168]]\n",
      "\n",
      "  [[0.1344891  0.22710135 0.25976662 0.2788671  0.30260047 0.27683158\n",
      "    0.27683158 0.2994152  0.26155811 0.27284839 0.26155811 0.25453642\n",
      "    0.2689782  0.24951267 0.24468339]\n",
      "   [0.24468339 0.47672253 0.58850575 0.72316384 0.73988439 0.76646707\n",
      "    0.72316384 0.82051282 0.8        0.66149871 0.69565217 0.63209877\n",
      "    0.60520095 0.56140351 0.51405622]\n",
      "   [0.34688347 0.74418605 1.03225806 1.33333333 1.42222222 1.6\n",
      "    1.68421053 1.61006289 1.6516129  1.55151515 1.41436464 1.39130435\n",
      "    1.30612245 1.024      1.024     ]]]\n",
      "\n",
      "\n",
      " [[[0.14960918 0.24788187 0.29173789 0.31086825 0.33464052 0.33662064\n",
      "    0.33862434 0.33074935 0.30750751 0.31430325 0.3196005  0.31604938\n",
      "    0.31086825 0.31430325 0.2962963 ]\n",
      "   [0.28515734 0.53333333 0.7150838  0.81528662 0.8707483  0.91428571\n",
      "    0.88888889 0.8951049  0.88275862 0.8707483  0.83116883 0.74853801\n",
      "    0.70718232 0.66149871 0.64646465]\n",
      "   [0.39233716 0.82580645 1.21904762 1.46285714 1.66233766 1.84172662\n",
      "    1.85507246 1.85507246 1.82857143 1.81560284 1.72972973 1.57055215\n",
      "    1.45454545 1.36898396 1.25490196]]\n",
      "\n",
      "  [[0.13066641 0.20838421 0.24788187 0.2830293  0.30099941 0.28951088\n",
      "    0.28731762 0.2689782  0.28731762 0.28731762 0.28731762 0.24156641\n",
      "    0.26155811 0.26337449 0.23703704]\n",
      "   [0.25453642 0.47940075 0.62745098 0.71910112 0.73563218 0.83116883\n",
      "    0.81012658 0.8        0.79503106 0.77575758 0.73142857 0.69565217\n",
      "    0.62745098 0.57270694 0.55053763]\n",
      "   [0.35779175 0.73563218 1.06666667 1.37634409 1.32642487 1.55151515\n",
      "    1.70666667 1.52380952 1.66233766 1.6        1.5147929  1.46285714\n",
      "    1.36898396 1.14285714 1.09401709]]]\n",
      "\n",
      "\n",
      " [[[0.14125112 0.25625626 0.30750751 0.3196005  0.32883751 0.33464052\n",
      "    0.32140615 0.31781502 0.33074935 0.32507937 0.32323232 0.31430325\n",
      "    0.31086825 0.32323232 0.30099941]\n",
      "   [0.28731762 0.54008439 0.68449198 0.8        0.87671233 0.88888889\n",
      "    0.91428571 0.8707483  0.88888889 0.8707483  0.81012658 0.7804878\n",
      "    0.69945355 0.66149871 0.64160401]\n",
      "   [0.39506173 0.80503145 1.17431193 1.47976879 1.67320261 1.79020979\n",
      "    1.82857143 1.85507246 1.84172662 1.82857143 1.69536424 1.56097561\n",
      "    1.44632768 1.32642487 1.24271845]]\n",
      "\n",
      "  [[0.13593522 0.22846943 0.26337449 0.27482555 0.28093278 0.30585424\n",
      "    0.27683158 0.28731762 0.2830293  0.29784759 0.28951088 0.25976662\n",
      "    0.2579995  0.24788187 0.2298541 ]\n",
      "   [0.25453642 0.47145488 0.60952381 0.68449198 0.82051282 0.78527607\n",
      "    0.77575758 0.77575758 0.82051282 0.72316384 0.71910112 0.58850575\n",
      "    0.65641026 0.52674897 0.48210923]\n",
      "   [0.34901159 0.75294118 1.04918033 1.25490196 1.53293413 1.6\n",
      "    1.77777778 1.69536424 1.68421053 1.50588235 1.40659341 1.3989071\n",
      "    1.17431193 1.09401709 1.08474576]]]\n",
      "\n",
      "\n",
      " [[[0.15802469 0.24468339 0.28951088 0.31604938 0.32140615 0.34270415\n",
      "    0.33862434 0.3196005  0.3196005  0.31781502 0.31781502 0.31781502\n",
      "    0.30585424 0.30421866 0.29399943]\n",
      "   [0.2830293  0.54008439 0.68449198 0.78527607 0.84768212 0.88275862\n",
      "    0.88275862 0.88275862 0.8590604  0.86486486 0.81528662 0.76190476\n",
      "    0.70718232 0.67368421 0.63209877]\n",
      "   [0.38180462 0.82051282 1.19626168 1.47976879 1.66233766 1.76551724\n",
      "    1.8028169  1.86861314 1.85507246 1.76551724 1.70666667 1.55151515\n",
      "    1.42222222 1.31958763 1.21904762]]\n",
      "\n",
      "  [[0.1323767  0.22710135 0.23556476 0.26708399 0.2962963  0.27284839\n",
      "    0.30917874 0.28731762 0.28093278 0.2830293  0.2962963  0.26337449\n",
      "    0.2579995  0.24951267 0.24156641]\n",
      "   [0.25625626 0.45149912 0.59259259 0.68449198 0.76646707 0.73988439\n",
      "    0.82580645 0.77575758 0.76646707 0.76190476 0.73988439 0.69565217\n",
      "    0.5577342  0.56140351 0.5300207 ]\n",
      "   [0.33662064 0.72316384 1.07563025 1.32642487 1.5147929  1.5147929\n",
      "    1.67320261 1.66233766 1.71812081 1.58024691 1.52380952 1.38378378\n",
      "    1.13274336 1.09401709 1.01587302]]]\n",
      "\n",
      "\n",
      " [[[0.13969033 0.2298541  0.27683158 0.31604938 0.31430325 0.31086825\n",
      "    0.32140615 0.32323232 0.3196005  0.31604938 0.31086825 0.30750751\n",
      "    0.31430325 0.29784759 0.2962963 ]\n",
      "   [0.26337449 0.50196078 0.66149871 0.77108434 0.86486486 0.8707483\n",
      "    0.8707483  0.8590604  0.88275862 0.84210526 0.81012658 0.74853801\n",
      "    0.71111111 0.65641026 0.63209877]\n",
      "   [0.37426901 0.81528662 1.17431193 1.44632768 1.64102564 1.71812081\n",
      "    1.76551724 1.82857143 1.81560284 1.77777778 1.6516129  1.52380952\n",
      "    1.41436464 1.29949239 1.23076923]]\n",
      "\n",
      "  [[0.13066641 0.22441376 0.25453642 0.28951088 0.2962963  0.27089947\n",
      "    0.26155811 0.26155811 0.26155811 0.25116507 0.28093278 0.25283951\n",
      "    0.25116507 0.24311491 0.25453642]\n",
      "   [0.24951267 0.44444444 0.60093897 0.65641026 0.76190476 0.75739645\n",
      "    0.75294118 0.79503106 0.8        0.67015707 0.71910112 0.62745098\n",
      "    0.5967366  0.53668763 0.50196078]\n",
      "   [0.32883751 0.72727273 1.03225806 1.20754717 1.38378378 1.44632768\n",
      "    1.58024691 1.54216867 1.56097561 1.55151515 1.46285714 1.42222222\n",
      "    1.17431193 1.06666667 1.06666667]]]]\n"
     ]
    }
   ],
   "source": [
    "print(learning_efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1562500065039063"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.86486486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
